{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bc0f252-03f7-482c-990b-1598c07294ef",
   "metadata": {
    "id": "4bc0f252-03f7-482c-990b-1598c07294ef"
   },
   "source": [
    "# Land Cover Type Classification with PyTorch\n",
    "\n",
    "This notebook serves as a starting point for your machine learning project on land cover type classification.\n",
    "\n",
    "The task at hand involves classifying land cover types, such as 'Forest,' 'River,' 'Highway,' and more, based on satellite images. The dataset consists of images labeled with their corresponding land cover types. The goal is to train a machine learning model that can accurately predict the land cover type of new, unseen images.\n",
    "\n",
    "In this notebook, you'll find code snippets to load and visualize the data, providing insights into the images and their labels.\n",
    "\n",
    "## Build Your Model\n",
    "\n",
    "You have the freedom to choose the architecture or model for your land cover classification task. Whether you opt for a simple convolutional neural network (CNN) or explore transfer learning with pre-trained models, the notebook provides a flexible starting point. Experiment with different architectures to achieve the best performance.\n",
    "\n",
    "## Model Training and Evaluation\n",
    "\n",
    "Once your model is defined, the notebook guides you through the process of training it on the dataset. Additionally, it includes code to evaluate the model's performance on the validation and test sets.\n",
    "\n",
    "Feel free to modify, experiment, and enhance the provided code. Happy coding !\n",
    "\n",
    "Please submit your weekly assignments to me via [email](mailto:elmontassir@cerfacs.fr) to receive your score on the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05256e61-7c8e-4431-9f2e-74247ca384ac",
   "metadata": {
    "id": "05256e61-7c8e-4431-9f2e-74247ca384ac"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f37bb45-445b-43bf-8cf5-e9b4d6083e4f",
   "metadata": {
    "id": "6f37bb45-445b-43bf-8cf5-e9b4d6083e4f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tarfile\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb6c0cf-ade4-4365-ac10-f7ef2455546e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbb6c0cf-ade4-4365-ac10-f7ef2455546e",
    "outputId": "b3305950-3941-439d-cd3b-18d8b4c44d24"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "  print(\"You are on GPU !\")\n",
    "else:\n",
    "  print('Change the runtime to GPU or continue with CPU, but this should slow down your trainings')\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60da492-9324-4523-b581-e0565f5d9654",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e60da492-9324-4523-b581-e0565f5d9654",
    "outputId": "82c7f9e8-b343-4823-d372-c218cd2c863f"
   },
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "!wget -nv https://cerfacs.fr/opendata/cours/data/TRAIN.tar\n",
    "!wget -nv https://cerfacs.fr/opendata/cours/data/TEST.tar\n",
    "!wget -nv https://cerfacs.fr/opendata/cours/data/y_train.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d131a4b-f23c-49c0-832b-fbf3d11d8ee3",
   "metadata": {
    "id": "1d131a4b-f23c-49c0-832b-fbf3d11d8ee3"
   },
   "outputs": [],
   "source": [
    "# Using tarfile to create np arrays\n",
    "def extract_files(dataset):\n",
    "    tar = tarfile.open(dataset+'.tar', 'r')\n",
    "    names = tar.getmembers()[:]\n",
    "    images = [tar.extractfile(name) for name in names]\n",
    "    return np.array([np.array(Image.open(image)) for image in images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9158e653-d33a-4408-a57c-5d3ecd87db82",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9158e653-d33a-4408-a57c-5d3ecd87db82",
    "outputId": "89e7ff47-77a2-414e-ed83-40c2d1ebb890"
   },
   "outputs": [],
   "source": [
    "X_train = extract_files('TRAIN')\n",
    "X_test = extract_files('TEST')\n",
    "y_train = np.load('y_train.npy').reshape(-1, 1)\n",
    "print(\"Train data : \",X_train.shape)\n",
    "print(\"Train labels\", y_train.shape)\n",
    "print(\"Test data : \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f16877-1245-4469-b098-c5290c2e57ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "c0f16877-1245-4469-b098-c5290c2e57ad",
    "outputId": "7bacb0db-937f-4c67-ae04-7faf59177177"
   },
   "outputs": [],
   "source": [
    "# Display data samples\n",
    "fig, axes = plt.subplots(2, 7, figsize=(15, 4))\n",
    "axes = axes.ravel()\n",
    "for i in range(14):\n",
    "    axes[i].imshow(X_train[i])\n",
    "    axes[i].set_title(y_train[i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cXkxp4MLFRFw",
   "metadata": {
    "id": "cXkxp4MLFRFw"
   },
   "source": [
    "There are 10 possible classes for each image (only one per image is correct):\n",
    "\n",
    "  - 'AnnualCrop'\n",
    "  - 'Forest'\n",
    "  - 'HerbaceousVegetation'\n",
    "  - 'Highway'\n",
    "  - 'Industrial'\n",
    "  - 'Pasture'\n",
    "  - 'PermanentCrop'\n",
    "  - 'Residential'\n",
    "  - 'River'\n",
    "  - 'SeaLake'\n",
    "\n",
    "We could simply code an integer value for each: 'AnnualCrop' = 0, 'Forest' = 1, etc... This is known as \"Ordinal Encoding\", and has some drawbacks, e.g. if the network is unsure whether it is class 0 or 2, it could end up saying 1, which is another class altogether. When categories have a natural order, ordinal encoding can be a good way to go. Here, this is not the case.\n",
    "\n",
    "The most classical way to convert the type of labels here to numeric values is through [**one-hot encoding**](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features). In this process, the label is converted to a vector with length the number of possible labels, and only the one matching the true label is set to 1, all others are set to 0.\n",
    "\n",
    "|                 | Type1 | Type2 | Type3 |   | Label Vector |\n",
    "|-----------------|:-----:|:-----:|:-----:|---|:------------:|\n",
    "| Sample1: Type 2 |   0   |   1   |   0   |   |   [0, 1, 0]  |\n",
    "| Sample2: Type 2 |   0   |   1   |   0   |   |   [0, 1, 0]  |\n",
    "| Sample3: Type 1 |   1   |   0   |   0   |   |   [1, 0, 0]  |\n",
    "| ...             |       |       |       |   |              |\n",
    "\n",
    "Scikit-learn has a useful class for this, [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), which does this automatically. More importantly, it remembers the encoding, and you can use it again after making your final predictions te *decode* them back to text labels, as expected by the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0cb062-cddf-445d-9f84-f518d45feecd",
   "metadata": {
    "id": "7a0cb062-cddf-445d-9f84-f518d45feecd"
   },
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoding\n",
    "encoder = OneHotEncoder()\n",
    "y_train = encoder.fit_transform(y_train).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce44b8c-e1a4-4277-9e27-46a8e9bd5042",
   "metadata": {
    "id": "6ce44b8c-e1a4-4277-9e27-46a8e9bd5042"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4a2462-0adc-4082-9c6b-07d5e7ce9610",
   "metadata": {
    "id": "fb4a2462-0adc-4082-9c6b-07d5e7ce9610"
   },
   "source": [
    "Note: the images here are encoded with 8-bit integers, *i.e.* between 0 and 255. A normalization is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4f0022-8a3d-4997-a071-ac524e5eea94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf4f0022-8a3d-4997-a071-ac524e5eea94",
    "outputId": "be73b938-14dc-436b-9f18-7de894f4fc63"
   },
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "X_train, X_test = X_train/255, X_test/255\n",
    "mean = np.mean(X_train, axis=(0, 1, 2))\n",
    "std = np.std(X_train, axis=(0, 1, 2))\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JLntFHEASH7e",
   "metadata": {
    "id": "JLntFHEASH7e"
   },
   "source": [
    "The normalization coefficients for the mean and standard deviation are commonly used for image data normalization within the range of [0, 255] or [0, 1]. This process brings pixel values into a standard range centered around zero, facilitating the acceleration of neural network training. In this case, we begin by dividing by 255 to scale values to [0, 1]. Subsequently, subtracting the mean centers the range around zero, and dividing by the standard deviation reduces the range to a centered Gaussian distribution, promoting stability.\n",
    "\n",
    "Normalization coefficients may vary depending on the dataset, image characteristics, and network architecture. Experimenting with different strategies is common in model development. For specific datasets, calculating the mean and standard deviation directly from the training data can provide a good normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qn5_TR9_GuHN",
   "metadata": {
    "id": "Qn5_TR9_GuHN"
   },
   "outputs": [],
   "source": [
    "# Assuming X_train and y_train are PyTorch tensors\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors and normalize images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "X_train_tensor = torch.stack([transform(img) for img in X_train]).float()\n",
    "X_valid_tensor = torch.stack([transform(img) for img in X_valid]).float()\n",
    "X_test_tensor = torch.stack([transform(img) for img in X_test]).float()\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "y_valid_tensor = torch.from_numpy(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zLmXU-bnHUHE",
   "metadata": {
    "deletable": false,
    "id": "zLmXU-bnHUHE",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ad5147f2265c61a50b2efa6562d5137",
     "grade": false,
     "grade_id": "model",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the simple CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        # ... (add more layers as needed)\n",
    "        # self.fc = nn.Linear(..., 10)  # Output has 10 classes\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # ... (add forward pass for other layers)\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZLo_SnfwGY5d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZLo_SnfwGY5d",
    "outputId": "9b4153ed-d1b4-4d94-84a8-a7409d2a60e0"
   },
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())  # You can set learning rate, weight decay, etc.\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor.argmax(dim=1))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_dataset = TensorDataset(X_valid_tensor, y_valid_tensor.argmax(dim=1))\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q9HHKknrG3F9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q9HHKknrG3F9",
    "outputId": "c5583ca7-d7ab-4e05-da36-f39a5a6f19e1"
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Validation Loss: {valid_loss / len(valid_loader):.3f}, Accuracy: {100*accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaefef8f-36e7-4e55-8590-9bdf60093542",
   "metadata": {
    "id": "aaefef8f-36e7-4e55-8590-9bdf60093542"
   },
   "source": [
    "# Create Your Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7cf307-efdb-40a0-a4bd-958201315ffd",
   "metadata": {
    "id": "2d7cf307-efdb-40a0-a4bd-958201315ffd"
   },
   "outputs": [],
   "source": [
    "# Function to create a submission file\n",
    "def create_submission(predictions):\n",
    "    assert predictions.shape == (7000, 1), f\"Wrong shape for your prediction file : {predictions.shape} instead of (7000, 1)\"\n",
    "    with open('predictions.npy', 'wb') as f:\n",
    "      np.save(f, predictions)\n",
    "    print(\"File predictions.npy created !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5TPnH02PMGJZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5TPnH02PMGJZ",
    "outputId": "d5dad42d-aa12-4cc7-ce3f-52bea8c48476"
   },
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "bs = 35\n",
    "predictions = np.ones((X_test_tensor.shape[0],10))\n",
    "for i in range(X_test_tensor.shape[0]//bs):\n",
    "  predictions[bs*i:bs*(i+1),:] = model(X_test_tensor[bs*i:bs*(i+1)].to(device)).cpu().detach().numpy()\n",
    "print(predictions[:5])\n",
    "\n",
    "# Get labels\n",
    "predictions = encoder.inverse_transform(predictions)\n",
    "print(predictions[:5])\n",
    "\n",
    "# Create a submission using the provided function\n",
    "NAME = \"NAME\"\n",
    "NUMBER = 1\n",
    "create_submission(predictions)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
