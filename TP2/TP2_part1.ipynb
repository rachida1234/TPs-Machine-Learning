{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSzS8JtZnR_V"
   },
   "source": [
    "# Practical session nÂ°2\n",
    "\n",
    "In Part I:\n",
    "- Training a CNN on MNIST. Comparison with a multi-layer perceptron.\n",
    "- Initialization methods, regularization methods.\n",
    "\n",
    "In Part II:\n",
    "\n",
    "- Learning on a graphics card.\n",
    "- Improving gradient descent: SGD with momentum and progressive learning rate decay (scheduler).\n",
    "- Transfer learning: fine-tuning and freezing.\n",
    "\n",
    "Duration: 2 h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Jp87bbda7qc"
   },
   "source": [
    "**Part I**\n",
    "\n",
    "\n",
    "Now that we have covered the basic building blocks, we will train a Convolutional Neural Network (CNN) on a slightly more challenging problem than separation of points in a 2D space: handwritten digit recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-6auA4Cc6xC"
   },
   "source": [
    "The dataset is named MNIST. It is located in the shared folder and comprises black and white (1 channel) images of 28x28 pixels. A specific dataset object is allocated to it in the torchvision.datasets module. The subsequent cells are designed to import packages, download the dataset, and showcase some images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eN2o2vVtaHcE"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtLw0uMvrbtj",
    "outputId": "9057a675-9bea-49fb-e8e7-dade5ef2a814"
   },
   "outputs": [],
   "source": [
    "root = '.'\n",
    "\n",
    "# transforms (format/normalization)\n",
    "tr=torchvision.transforms.Compose([\n",
    "   torchvision.transforms.ToTensor(),\n",
    "   torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "   ])\n",
    "\n",
    "# Definition of training sets:\n",
    "ds = {'train': torchvision.datasets.MNIST(root='./data',\n",
    "                                          train = True,\n",
    "                                          download = True,\n",
    "                                          transform = tr\n",
    "                                          ),\n",
    "      'val': torchvision.datasets.MNIST(root='./data',\n",
    "                                        train = False,\n",
    "                                        download = True,\n",
    "                                        transform = tr)\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MyYZ8PBCan6c",
    "outputId": "a0193159-ddfd-4b37-b5e2-174a2822d700"
   },
   "outputs": [],
   "source": [
    "phases = ['train','val']\n",
    "\n",
    "# Dataloaders:\n",
    "bs = 8\n",
    "loader ={x :  DataLoader(ds[x], batch_size=bs, shuffle=True, num_workers = 4) for x in phases}\n",
    "# To parallelize the loading of thumbnails into RAM:\n",
    "num_workers = 2\n",
    "# (data loading is thus parallelized, for even faster performance, we will use a GPU - see Part II)\n",
    "\n",
    "# Sizes (for score calculation)\n",
    "dataset_sizes = {x: len(ds[x]) for x in  phases}\n",
    "\n",
    "# we fix the random number generator\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "AJ5jwbPKarBT",
    "outputId": "84f95446-fa07-4b8a-b4d5-c7da1d0bd90c"
   },
   "outputs": [],
   "source": [
    "x, t = next(iter(loader['train']))\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(8):\n",
    "  plt.subplot(4,2,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(x[i,0,:,:], cmap='gray') #, interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(t[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWHzA-82fq_7"
   },
   "source": [
    "Now, we will define a shallow CNN (two convolution layers).\n",
    "\n",
    "**Exercise:**  Determine *N* in such a way that the network can accept MNIST images as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "BRQ6P0duauRr",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f4a00cb970e29a4b33ed48e7798bd44",
     "grade": false,
     "grade_id": "cell-caf94083627c780a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# N = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, padding =2)\n",
    "        self.conv2 = nn.Conv2d(10, 10, kernel_size=5, padding =2)\n",
    "        self.fc1 = nn.Linear(N, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, N)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        # Here, the log is applied after the softmax:\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_GdrC04hvjL"
   },
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "# We select the log likelihoods for the true classes:\n",
    "loss_fn =  torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zP49HEuzhu8k"
   },
   "source": [
    "The training loop has two phases: weights are updated only in the first phase dedicated to training. During the validation phase, generalization performance on independent images is monitored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHltWFJYCI3n",
    "outputId": "4a93cfa3-02d3-43da-ee60-dfcd0e6289be"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Initialize time\n",
    "start_time = time.time()\n",
    "\n",
    "# Learning Loop:\n",
    "for epoch in range(6):\n",
    "    print(f'Epoch: {epoch}')\n",
    "\n",
    "    running_loss_train = 0.0\n",
    "    running_corrects_train = 0\n",
    "    running_loss_val = 0.0\n",
    "    running_corrects_val = 0\n",
    "\n",
    "    # Phase 1: Training\n",
    "    model.train()  # Set the model to training mode\n",
    "    for x, label in loader['train']:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get predicted classes:\n",
    "        _, preds = torch.max(output, 1)\n",
    "\n",
    "        # Update counters:\n",
    "        running_loss_train += loss.item() * x.shape[0]\n",
    "        running_corrects_train += torch.sum(preds == label.data)\n",
    "\n",
    "    # Calculate training scores:\n",
    "    epoch_loss_train = running_loss_train / dataset_sizes['train']\n",
    "    epoch_acc_train = running_corrects_train.float() / dataset_sizes['train']\n",
    "\n",
    "    print(f'Train Loss: {epoch_loss_train:.4f} Acc: {epoch_acc_train:.4f}')\n",
    "\n",
    "    # Phase 2: Validation\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, label in loader['val']:\n",
    "            output = model(x)\n",
    "            loss = loss_fn(output, label)\n",
    "\n",
    "            # Get predicted classes:\n",
    "            _, preds = torch.max(output, 1)\n",
    "\n",
    "            # Update counters:\n",
    "            running_loss_val += loss.item() * x.shape[0]\n",
    "            running_corrects_val += torch.sum(preds == label.data)\n",
    "\n",
    "    # Calculate validation scores and print:\n",
    "    epoch_loss_val = running_loss_val / dataset_sizes['val']\n",
    "    epoch_acc_val = running_corrects_val.float() / dataset_sizes['val']\n",
    "\n",
    "    print(f'Validation Loss: {epoch_loss_val:.4f} Acc: {epoch_acc_val:.4f}')\n",
    "\n",
    "    # Print elapsed time:\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Time: {round(elapsed_time)} seconds')\n",
    "\n",
    "    # Update start time for the next epoch\n",
    "    start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZQq3pNGnuD0"
   },
   "source": [
    "**Exercise**:\n",
    "At each epoch, store the accuracy and the cost function value in the lists train_losses, val_losses, train_accs, and val_accs.\n",
    "Plot the **learning curves** over six epochs. \\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "kWQvoDL4yNAP",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7b4ea5eb87c61051234e188a2007c01",
     "grade": false,
     "grade_id": "cell-ad40e631509f5fff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "a7891966-f3ce-4e96-d114-f5c07604f2a1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "deletable": false,
    "id": "vjUhzOuWuKvU",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9c23a150fa8ae057d3b9d2047fa76d0",
     "grade": false,
     "grade_id": "cell-29721af3359f5f0c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "b671a5d7-bfeb-4dd6-d461-31f58a27d3c3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.title('accuracy = f(epoch)')\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "deletable": false,
    "id": "IzEGdnJ-y0mO",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "432755386cf98d94cbb1de8e2cad4318",
     "grade": false,
     "grade_id": "cell-1f710c6281b43308",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "a7269947-53ea-4d2d-c348-0e88651b186d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots()\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPJ1inr0ru_9"
   },
   "source": [
    "**Exercise:** Take the two-layer perceptron (fc1 and fc2) from the TP1 part 2 and modify it to directly take MNIST images as input.\n",
    "Compare the standalone perceptron to the CNN in terms of size (number of weights) and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "kTVMO0md1cfA",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3096640b9fb445e25b08f217c35c760",
     "grade": false,
     "grade_id": "cell-8d7d9ddad78b7109",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "rw9NdP5nz2mg",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d0e505f79083e1a31eefb0cff7212b9",
     "grade": false,
     "grade_id": "cell-478962a7815b241c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "61d52aee-38c2-4196-b2c9-342b7f43f258",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Comparaison des tailles:\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "12qtwUymACjF",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7890c72b9472e63d04df03cd7c9308f",
     "grade": false,
     "grade_id": "cell-0292185aff8e14bf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "a5a92cb4-780d-41bf-e81c-8b30ce4b939f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Performance comparison (on the validation set):\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSjokBh7zZ7m"
   },
   "source": [
    "**Note:** It is not easy to improve scores with a larger perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2sh9EeMuuks"
   },
   "outputs": [],
   "source": [
    "class BiggerPerceptron(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BiggerPerceptron, self).__init__()\n",
    "        self.fc01 = nn.Linear(28*28, 50)\n",
    "        self.fc02 = nn.Linear(50, 200)\n",
    "        self.fc1 = nn.Linear(200, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc01(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc02(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6u3KZH3nviP3"
   },
   "outputs": [],
   "source": [
    "bigger_perceptron = BiggerPerceptron()\n",
    "optimizer = torch.optim.Adam(bigger_perceptron.parameters(), lr = 0.001)\n",
    "loss_fn =  torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hq10q0mvqJtY",
    "outputId": "5b65c2df-1448-4efe-f0b7-f032e340f34c"
   },
   "outputs": [],
   "source": [
    "# bigger_perceptron :\n",
    "nb_weights = 0\n",
    "for module in bigger_perceptron.modules():\n",
    "  if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "    for parameter in module.parameters():\n",
    "      nb_weights += torch.numel(parameter)\n",
    "print(nb_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pt-dV_-Ka2hC",
    "outputId": "096ad01a-86f1-4b0b-c2fa-504c4e3d215a"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "\n",
    "train_losses_p = []\n",
    "val_losses_p = []\n",
    "\n",
    "train_accs_p= []\n",
    "val_accs_p = []\n",
    "\n",
    "loader ={x :  DataLoader(ds[x], batch_size=bs, shuffle=True, num_workers = 4) for x in phases}\n",
    "\n",
    "#training loop:\n",
    "for epoch in range(15):\n",
    "    print('epoch :' + str(epoch))\n",
    "\n",
    "    running_loss_train = 0.\n",
    "    running_corrects_train = 0.\n",
    "    running_loss_val = 0.\n",
    "    running_corrects_val = 0.\n",
    "\n",
    "    for x, label in loader['train']:\n",
    "        optimizer.zero_grad()\n",
    "        output = bigger_perceptron(x)\n",
    "        l = loss_fn(output, label)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, preds = torch.max(output, 1)\n",
    "        running_loss_train += l.item() * x.shape[0]\n",
    "        running_corrects_train += torch.sum(preds == label.data)\n",
    "\n",
    "    epoch_loss_train = running_loss_train / dataset_sizes['train']\n",
    "    epoch_acc_train = running_corrects_train.float() / dataset_sizes['train']\n",
    "\n",
    "    train_losses_p.append(epoch_loss_train)\n",
    "    train_accs_p.append(epoch_acc_train)\n",
    "\n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "        'train', epoch_loss_train, epoch_acc_train))\n",
    "\n",
    "    bigger_perceptron.eval()\n",
    "\n",
    "    for x, label in loader['val']:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = bigger_perceptron(x)\n",
    "            l = loss_fn(output, label)\n",
    "\n",
    "        _, preds = torch.max(output, 1)\n",
    "        running_loss_val += l.item() * x.shape[0]\n",
    "        running_corrects_val += torch.sum(preds == label.data)\n",
    "\n",
    "    epoch_loss_val = running_loss_val / dataset_sizes['val']\n",
    "    epoch_acc_val = running_corrects_val.float() / dataset_sizes['val']\n",
    "\n",
    "    val_losses_p.append(epoch_loss_val)\n",
    "    val_accs_p.append(epoch_acc_val)\n",
    "\n",
    "\n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "        'val', epoch_loss_val, epoch_acc_val))\n",
    "\n",
    "    new_t = time.time()\n",
    "    print('time ' +str(round(new_t- t)))\n",
    "    t = new_t\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
